Замечание:
1) Эксперименты проводились с моделью, учитывающей структуру слов и их контекст, SentenceLevelPOSTagger.
2) Настройки указываются для вспомогательной сверточной архитектуры StackedConv1d.

Итоговый отчет после экспериментов и доработок:

1) Эксперимент: пайплайн с первоначальными настройками.
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 84370

Итоги:
- среднее значение функции потерь на обучении: 0.010680453851819038
- macro avg f1 на обучении: 0.92
- среднее значение функции потерь на валидации: 0.01484402734786272
- macro avg f1 на валидации: 0.89
- примерное время на одну эпоху (в секундах): 14

Результаты применения теггеров:
# мама-NOUN мыла-NOUN раму-ADV

# косил-VERB косой-NOUN косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-NOUN дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN

# три-NUM да-PART три-NUM будет-AUX дырка-NOUN

# три-NUM да-PART три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Довольно хорошее итоговое качество на валидации.

###

2) Эксперимент: увеличение размера эмбеддинга (с 64 до 128).
Настройки: EPOCH_N = 10, EMB_SIZE = 128, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 316178

Итоги:
- среднее значение функции потерь на обучении: 0.008393769152462482
- macro avg f1 на обучении: 0.93
- среднее значение функции потерь на валидации: 0.013538648374378681
- macro avg f1 на валидации: 0.90
- примерное время на одну эпоху (в секундах): 24

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-NOUN

# косил-VERB косой-NOUN косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX шесть-VERB

# сорок-NOUN сорок-NOUN

Выводы:
Качество на обучении и валидации выросло, но модель стала немного переобучаться и обучение дольше длится.

###

3) Эксперимент: размера эмбеддинга взят равным 128 и увеличена сила dropout с 0.3 до 0.5.
Настройки: EPOCH_N = 10, EMB_SIZE = 128, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.5, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 316178

Итоги:
- среднее значение функции потерь на обучении: 0.013492310419678688
- macro avg f1 на обучении: 0.92
- среднее значение функции потерь на валидации: 0.017639821395277977
- macro avg f1 на валидации: 0.89
- примерное время на одну эпоху (в секундах): 24

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-NOUN

# косил-VERB косой-ADJ косой-ADJ косой-NOUN

# глокая-ADJ куздра-NOUN штеко-NOUN будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB

# ведро-ADV дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN

# три-NUM да-NOUN три-NUM будет-AUX дырка-NOUN

# три-NUM да-NOUN три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Модель стала обучаться дольше, качество не изменилось.

###

4) Эксперимент: увеличение количества слоев для StackedConv1d с 3 до 10.
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 10, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 257298

Итоги:
- среднее значение функции потерь на обучении: 0.009937995113432407
- macro avg f1 на обучении: 0.88
- среднее значение функции потерь на валидации: 0.01434558629989624
- macro avg f1 на валидации: 0.87
- примерное время на одну эпоху (в секундах): 36

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-NOUN

# косил-VERB косой-ADJ косой-ADJ косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB

# ведро-ADV дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX шесть-VERB

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели снизилось, модель обучается дольше и происходит переобучение.

###

5) Эксперимент: увеличение количества слоев для StackedConv1d с 3 до 6 и увеличение силы dropout с 0.3 до 0.4.
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 6, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.4, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 158482

Итоги:
- среднее значение функции потерь на обучении: 0.011968573555350304
- macro avg f1 на обучении: 0.90
- среднее значение функции потерь на валидации: 0.015789790078997612
- macro avg f1 на валидации: 0.89
- примерное время на одну эпоху (в секундах): 23

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-NOUN

# косил-VERB косой-NOUN косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB

# ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB

# три-NUM да-PART три-NUM будет-AUX дырка-NOUN

# три-NUM да-PART три-NUM будет-AUX шесть-VERB

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели на обучении снизилось, качество модели на валидации не изменилось.

###

6) Эксперимент: увеличение размера ядра свертки с 3 до 5.
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 5, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 133522

Итоги:
- среднее значение функции потерь на обучении: 0.00852733850479126
- macro avg f1 на обучении: 0.91
- среднее значение функции потерь на валидации: 0.01325085386633873
- macro avg f1 на валидации: 0.87
- примерное время на одну эпоху (в секундах): 16

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-NOUN

# косил-VERB косой-ADJ косой-ADJ косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADJ будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-NOUN

# три-NUM да-PART три-NUM будет-AUX дырка-NOUN

# три-NUM да-PART три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели на обучении снизилось, качество модели на валидации также снизилось.

###

7) Эксперимент: увеличение количества эпох с 10 до 100.
Настройки: EPOCH_N = 100, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 84370

Итоги:
- среднее значение функции потерь на обучении: 0.005172078497707844
- macro avg f1 на обучении: 0.96
- среднее значение функции потерь на валидации: 0.011200067587196827
- macro avg f1 на валидации: 0.92
- примерное время на одну эпоху: 14

Результаты применения теггеров:
# мама-NOUN мыла-NOUN раму-NOUN

# косил-VERB косой-ADJ косой-ADJ косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-VERB

# ведро-NOUN дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB

# три-NUM да-PART три-NUM будет-AUX дырка-NOUN

# три-NUM да-PART три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Модель обучалась 80 эпох. Качество модели на обучении и на валидации значительно улучшилось, но модель немного переобучается.

###

8) Эксперимент: убрал dropout и добавил пакетную нормализацию (перед функцией активации).
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = True
Количество параметров: 85138

Итоги:
- среднее значение функции потерь на обучении: 0.007908038794994354
- macro avg f1 на обучении: 0.92
- среднее значение функции потерь на валидации: 0.014366710558533669
- macro avg f1 на валидации: 0.90
- примерное время на одну эпоху (в секундах): 18

Результаты применения теггеров:

Выводы:
Качество модели стало выше, как на обучении, так и на валидации, но модель немного переобучается.

###

9) Эксперимент: убрал dropout и добавил пакетную нормализацию (после функции активации), увеличил количество слоев с 3 до 7.
Настройки: EPOCH_N = 10, EMB_SIZE = 64, LAYERS_N = 7, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = True
Количество параметров: 184722

Итоги:
- среднее значение функции потерь на обучении: 0.00850608479231596
- macro avg f1 на обучении: 0.93
- среднее значение функции потерь на валидации: 0.015494621358811855
- macro avg f1 на валидации: 0.89
- примерное время на одну эпоху (в секундах): 36

Результаты применения теггеров:
# мама-NOUN мыла-NOUN раму-ADV

# косил-VERB косой-NOUN косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-ADV

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-ADV

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-ADV дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB

# три-NUM да-PART три-NUM будет-VERB дырка-ADV

# три-NUM да-PART три-NUM будет-AUX шесть-VERB

# сорок-NOUN сорок-NOUN

Выводы:
На обучении качество модели немного увеличилось, на валидации осталось прежним. Модель немного переобучается.

###

10) Эксперимент: увеличение числа эпох с 10 до 20, добавление dilated-сверток.
Настройки: EPOCH_N = 20, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = [1, 2, 3], DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 84370

Итоги:
- среднее значение функции потерь на обучении: 0.007392780389636755
- macro avg f1 на обучении: 0.93
- среднее значение функции потерь на валидации: 0.012131263501942158
- macro avg f1 на валидации: 0.91
- примерное время на одну эпоху (в секундах): 13

Результаты применения теггеров:
# мама-NOUN мыла-VERB раму-ADV

# косил-VERB косой-ADJ косой-ADJ косой-NOUN

# глокая-ADJ куздра-NOUN штеко-NOUN будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-NOUN дало-VERB течь-VERB вода-NOUN стала-VERB течь-ADV

# три-NUM да-CCONJ три-NUM будет-VERB дырка-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели стало выше, как на обучении, так и на валидации, но модель немного переобучается.

###

11) Эксперимент: увеличение числа эпох с 10 до 20, dilated-свертки, увеличение размера ядра для последних слоев.
Настройки: EPOCH_N = 20, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = [3, 4, 5], DILATIONS = [1, 2, 3], DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 108946

Итоги:
- среднее значение функции потерь на обучении: 0.00734193529933691
- macro avg f1 на обучении: 0.93
- среднее значение функции потерь на валидации: 0.012154691852629185
- macro avg f1 на валидации: 0.91
- примерное время на одну эпоху (в секундах): 15

Результаты применения теггеров:
# мама-NOUN мыла-NOUN раму-NOUN

# косил-VERB косой-NOUN косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-NOUN будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-VERB мама-NOUN любит-VERB печь-NOUN

# ведро-NOUN дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB

# три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели стало выше, как на обучении, так и на валидации, но модель немного переобучается.

###

12) Эксперимент: увеличение числа эпох с 10 до 20, добавление dilated-сверток, увеличение силы dropout с 0.3 до 0.5.
Настройки: EPOCH_N = 20, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = [1, 2, 3], DROPOUT = 0.5, BATCH_NORMALIZATION = False, CRITERION = F.cross_entropy
Количество параметров: 84370

Итоги:
- среднее значение функции потерь на обучении: 0.01348417904227972
- macro avg f1 на обучении: 0.91
- среднее значение функции потерь на валидации: 0.017405228689312935
- macro avg f1 на валидации: 0.90
- примерное время на одну эпоху (в секундах): 13

Результаты применения теггеров:
# мама-NOUN мыла-NOUN раму-NOUN

# косил-VERB косой-ADJ косой-NOUN косой-NOUN

# глокая-ADJ куздра-NOUN штеко-NOUN будланула-NOUN бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN

# сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN

# пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN

# ведро-ADV дало-NOUN течь-NOUN вода-NOUN стала-VERB течь-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN

# три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM

# сорок-NOUN сорок-NOUN

Выводы:
Качество модели на валидации немного выше, но на качество на обучении немного снизилось.

###

13) Эксперимент: взвешивание классов с nn.CrossEntropyLoss(weight=class_weights,reduction='mean').cuda().
Настройки: EPOCH_N = 20, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = nn.CrossEntropyLoss(weight=class_weights,reduction='mean').cuda()
Количество параметров: 84370


Итоги:
- среднее значение функции потерь на обучении: 0.019179165363311768
- macro avg f1 на обучении: 0.86
- среднее значение функции потерь на валидации: 0.022933149710297585
- macro avg f1 на валидации: 0.83
- примерное время на одну эпоху (в секундах): 15

Результаты применения теггеров:

Выводы:

###

14) Эксперимент: взвешивание классов с nn.CrossEntropyLoss(weight=class_weights,reduction='sum').cuda().
Настройки: EPOCH_N = 20, EMB_SIZE = 64, LAYERS_N = 3, KERNELS = 3, DILATIONS = 1, DROPOUT = 0.3, BATCH_NORMALIZATION = False, CRITERION = nn.CrossEntropyLoss(weight=class_weights,reduction='sum').cuda()
Количество параметров: 84370


Итоги:
- среднее значение функции потерь на обучении: 
- macro avg f1 на обучении: 
- среднее значение функции потерь на валидации: 
- macro avg f1 на валидации: 
- примерное время на одну эпоху (в секундах): 

Результаты применения теггеров:

Выводы:

###