Итоговый отчет после экспериментов и доработок:

1) Эксперимент: взвешивание признаков с помощью TF-IDF. 
Пайплайн: TF-IDF + MinMaxScaler (custom) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.0022322218865156174
- доля верных ответов на обучении: 0.9994696835778681
- среднее значение функции потерь на валидации: 0.9289456605911255
- доля верных ответов на валидации: 0.76805629314923

Выводы:
Удовлетворительное качество на тестовой выборке, модель переобучается (значение функции потерь на тестовой выборке на два порядка больше, чем на обучающей).

###

2) Эксперимент: взвешивание признаков с помощью TF. 
Пайплайн: TF + MinMaxScaler (custom) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.0067640431225299835
- доля верных ответов на обучении: 0.9992045253668022
- среднее значение функции потерь на валидации: 0.6510777473449707
- доля верных ответов на валидации: 0.8182421667551779

Выводы:
Достаточно хорошее качество на тестовой выборке (лучше, чем для TF-IDF), модель переобучается.

###

3) Эксперимент: взвешивание признаков с помощью IDF. 
Пайплайн: IDF + MinMaxScaler (custom) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.020325081422924995
- доля верных ответов на обучении: 0.998585822874315
- среднее значение функции потерь на валидации: 1.0271177291870117
- доля верных ответов на валидации: 0.747344662772172

Выводы:
Удовлетворительное качество на тестовой выборке, модель переобучается.

###

4) Эксперимент: взвешивание признаков с помощью BIN. 
Пайплайн: BIN + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.21341334283351898
- доля верных ответов на обучении: 0.9752519003005127
- среднее значение функции потерь на валидации: 3.603476047515869
- доля верных ответов на валидации: 0.7261019649495486

Выводы:
Удовлетворительное качество на тестовой выборке, модель немного переобучается.

###

5) Реализовал PMI взвешивание, провел эксперимент со взвешиванием признаков с помощью PMI. 
Пайплайн: PMI + MinMaxScaler (custom) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.06604855507612228
- доля верных ответов на обучении: 0.9908078486830475
- среднее значение функции потерь на валидации: 1.36164391040802
- доля верных ответов на валидации: 0.79182156133829

Выводы:
Удовлетворительное качество на тестовой выборке (лучше, чем у TF-IDF, но хуже, чем у TF), модель переобучается.

###

6) Эксперимент: взвешиванием признаков с помощью TF-PMI. 
Пайплайн: TF-PMI + MinMaxScaler (custom) + LogReg

Итоги:
- среднее значение функции потерь на обучении: 0.0008423970430158079
- доля верных ответов на обучении: 0.9996464557185788
- среднее значение функции потерь на валидации: 0.6214731931686401
- доля верных ответов на валидации: 0.8297928836962294

Выводы:
Достаточно хорошее качество на тестовой выборке (лучше, чем для TF-IDF), но модель сильно переобучается.

###

7) Эксперимент: векторизация и обучение без масштабирования. 
Пайплайн: TF-IDF + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 2.8420400619506836
- доля верных ответов на обучении: 0.9591656354958459
- среднее значение функции потерь на валидации: 23.618478775024414
- доля верных ответов на валидации: 0.6737918215613383

Выводы:
Качество на тестовой выборке довольно низкое, модель немного переобучается.

###

8) Эксперимент: взвешивание признаков с помощью TF-IDF. 
Пайплайн: TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.011972295120358467
- доля верных ответов на обучении: 0.998850981085381
- среднее значение функции потерь на валидации: 1.663438320159912
- доля верных ответов на валидации: 0.737254381306426

Выводы:
Удовлетворительное качество на тестовой выборке, модель переобучается. Результаты немного хуже, чем для кастомного MinMaxScaler.

###

9) Эксперимент: масштабирование с StandardScaler из sklearn. 
Пайплайн: TF-IDF + StandardScaler (sklearn) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 0.9153491258621216
- доля верных ответов на обучении: 0.9962877850450769
- среднее значение функции потерь на валидации: 546.7008056640625
- доля верных ответов на валидации: 0.6343600637280935

Выводы:
Качество на тестовой выборке довольно низкое, модель сильно переобучается.

###

10) Эксперимент: масштабирование с RobustScaler из sklearn. 
Пайплайн: TF-IDF + RobustScaler (sklearn) + LogReg + Adam

Итоги:
- среднее значение функции потерь на обучении: 3.3818411827087402
- доля верных ответов на обучении: 0.9516528195156443
- среднее значение функции потерь на валидации: 23.75653076171875
- доля верных ответов на валидации: 0.6727296866702072

Выводы:
Качество на тестовой выборке довольно низкое, модель немного переобучается.

###

11) Эксперимент: добавление L2-регуляризации (был выбран коэффициент регуляризации со значением 1e-10). 
Пайплайн: TF-IDF + MinMaxScaler (custom) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.007722028996795416
- доля верных ответов на обучении: 0.9992929114371575
- среднее значение функции потерь на валидации: 1.0556082725524902
- доля верных ответов на валидации: 0.7485395645246946

Выводы:
Удовлетворительное качество на тестовой выборке, модель переобучается. Регуляризация в данном случае не помогла.

###

12) Эксперимент: добавление L2-регуляризации и масштабирование MinMaxScaler из sklearn (был выбран коэффициент регуляризации со значением 1e-4). 
Пайплайн: TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.15055498480796814
- доля верных ответов на обучении: 0.9972600318189854
- среднее значение функции потерь на валидации: 0.8660550117492676
- доля верных ответов на валидации: 0.8049654806160382

Выводы:
Достаточно хорошее качество на тестовой выборке, модель практически не переобучается.

###

13) Эксперимент: добавление стемминга и удаление стоп-слов. 
Пайплайн: (Stop word Removal + Stemming) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.2824912965297699
- доля верных ответов на обучении: 0.9830298744917801
- среднее значение функции потерь на валидации: 0.9560955166816711
- доля верных ответов на валидации: 0.7685873605947955

Выводы:
Удовлетворительное качество на тестовой выборке, модель практически не переобучается.

###

14) Эксперимент: добавление стемминга и удаление стоп-слов. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.15884242951869965
- доля верных ответов на обучении: 0.9973484178893406
- среднее значение функции потерь на валидации: 0.8458333015441895
- доля верных ответов на валидации: 0.8069569835369091

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается.

###

15) Эксперимент: добавление стемминга и удаление стоп-слов, использование TF вместо TF-IDF. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.16451728343963623
- доля верных ответов на обучении: 0.9968181014672087
- среднее значение функции потерь на валидации: 0.8431893587112427
- доля верных ответов на валидации: 0.8068242166755177

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается. Такой же результат, как и в случае использования TF-IDF.

###

16) Эксперимент: использование MLP вместо LogReg. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + MLP (sigmoid) + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.02239454723894596
- доля верных ответов на обучении: 0.9993812975075128
- среднее значение функции потерь на валидации: 0.7292893528938293
- доля верных ответов на валидации: 0.7999203398831651

Выводы:
Довольно хорошее качество на тестовой выборке, модель немного переобучается.

###

17) Эксперимент: использование MLP с ReLU. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + MLP (ReLU) + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.3825271427631378
- доля верных ответов на обучении: 0.8771433622061163
- среднее значение функции потерь на валидации: 1.4777909517288208
- доля верных ответов на валидации: 0.6274561869357408

Выводы:
Довольно низкое качество на тестовой выборке, модель немного переобучается.

###

18) Эксперимент: замена Adam на SGD. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + LogReg + SGD + L2

Итоги:
- среднее значение функции потерь на обучении: 0.12535066902637482
- доля верных ответов на обучении: 0.9976135761004066
- среднее значение функции потерь на валидации: 0.7666826844215393
- доля верных ответов на валидации: 0.8092140201805629

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается. Замена Adam на SGD не дала значительного прироста к качеству.

###

19) Эксперимент: использование оптимизатора Adagrad. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adagrad + L2

Итоги:
- среднее значение функции потерь на обучении: 0.20902366936206818
- доля верных ответов на обучении: 0.9983206646632491
- среднее значение функции потерь на валидации: 0.8890098929405212
- доля верных ответов на валидации: 0.8113382899628253

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается.

###

20) Эксперимент: использование оптимизатора RMSprop. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + LogReg + RMSprop + L2

Итоги:
- среднее значение функции потерь на обучении: 0.2245560586452484
- доля верных ответов на обучении: 0.9918684815273113
- среднее значение функции потерь на валидации: 0.8574509620666504
- доля верных ответов на валидации: 0.8056293149229952

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается.

###

21) Эксперимент: использование оптимизатора Adadelta. 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adadelta + L2

Итоги:
- среднее значение функции потерь на обучении: 0.503998875617981
- доля верных ответов на обучении: 0.9540392434152377
- среднее значение функции потерь на валидации: 1.0158753395080566
- доля верных ответов на валидации: 0.7969994689325545

Выводы:
Довольно хорошее качество на тестовой выборке, модель практически не переобучается.

###

22) Эксперимент: извлечение признаков из N-грамм. NGRAM_RANGE = (1,2). 
Пайплайн: (Stop word Removal + Lemmatizing) + NGRAM_RANGE (1,2) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.06983952969312668
- доля верных ответов на обучении: 0.9983206646632491
- среднее значение функции потерь на валидации: 0.82575923204422
- доля верных ответов на валидации: 0.8104089219330854

Выводы:
Довольно хорошее качество на тестовой выборке, модель немного переобучается.

###

23) Эксперимент: коррекция MIN_COUNT и MAX_DF. MAX_DF = 0.8 и MIN_COUNT = 4. Использование N-грамм с диапазоном (1,2). 
Пайплайн: (Stop word Removal + Lemmatizing) + NGRAM_RANGE (1,2) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.061165399849414825
- доля верных ответов на обучении: 0.998850981085381
- среднее значение функции потерь на валидации: 0.8257015347480774
- доля верных ответов на валидации: 0.812931492299522

Выводы:
Довольно хорошее качество на тестовой выборке, модель немного переобучается.

###

24) Эксперимент: добавление стемминга и удаление стоп-слов. 
Пайплайн: (Stop word Removal + Lemmatizing + NER Tagging) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.2438182830810547
- доля верных ответов на обучении: 0.9930175004419304
- среднее значение функции потерь на валидации: 1.0240169763565063
- доля верных ответов на валидации: 0.7566383430695698

Выводы:
Удовлетворительное качество на тестовой выборке, модель немного переобучается.

###

25) Эксперимент: добавление стемминга и удаление стоп-слов. 
Пайплайн: (Stop word Removal + Lemmatizing + NER Removal) + TF-IDF + MinMaxScaler (sklearn) + LogReg + Adam + L2

Итоги:
- среднее значение функции потерь на обучении: 0.25529319047927856
- доля верных ответов на обучении: 0.99151493724589
- среднее значение функции потерь на валидации: 1.0404458045959473
- доля верных ответов на валидации: 0.7535847052575677

Выводы:
Удовлетворительное качество на тестовой выборке, модель немного переобучается.

###

26) Эксперимент: TF-IDF (sublinear mode for TF). 
Пайплайн: (Stop word Removal + Lemmatizing) + SublinearTF-IDF + MinMaxScaler (sklearn) + LogReg + Adagrad + L2

Итоги:
- среднее значение функции потерь на обучении: 1.5216268301010132
- доля верных ответов на обучении: 0.7567615343821814
- среднее значение функции потерь на валидации: 1.832345962524414
- доля верных ответов на валидации: 0.6277217206585236

Выводы:
Довольно низкое качество на тестовой выборке, но модель не переобучается.

###

27) Эксперимент: TF-IDF (sublinear mode for IDF). 
Пайплайн: (Stop word Removal + Lemmatizing) + TF-SublinearIDF + MinMaxScaler (sklearn) + LogReg + Adagrad + L2

Итоги:
- среднее значение функции потерь на обучении: 2.3180344104766846
- доля верных ответов на обучении: 0.5922750574509458
- среднее значение функции потерь на валидации: 2.480306625366211
- доля верных ответов на валидации: 0.4604354753053638

Выводы:
Довольно низкое качество на тестовой выборке, но модель не переобучается.