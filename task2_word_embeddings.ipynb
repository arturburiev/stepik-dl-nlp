{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:30.785285Z",
     "start_time": "2019-10-29T19:19:29.542846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "import dlnlputils\n",
    "from dlnlputils.data import (\n",
    "    tokenize_text_simple_regex,\n",
    "    tokenize_corpus,\n",
    "    build_vocabulary,\n",
    "    texts_to_token_ids,\n",
    "    PaddedSequenceDataset,\n",
    "    Embeddings,\n",
    ")\n",
    "from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "from dlnlputils.visualization import plot_vectors\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных и подготовка корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:31.270503Z",
     "start_time": "2019-10-29T19:19:30.787789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка 125344\n",
      "Тестовая выборка 53719\n",
      "\n",
      "1/4 cup sour cream\n",
      "10 ounces swordfish, red snapper or other firm-fleshed fish\n",
      "1 tablespoon minced basil leaves\n",
      "Handful fresh parsley, finely minced\n",
      "4 ounces lard or butter, plus more for brushing tops\n",
      "4 to 5 green cardamom pods\n",
      "1 stick ( 1/4 pound) unsalted butter, softened\n",
      "1/4 teaspoon red pepper flakes, preferably Turkish or Aleppo (see note), more to taste\n",
      "1 tablespoon fresh lemon juice\n",
      "1/4 cup scallions, thinly sliced\n"
     ]
    }
   ],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "full_dataset = list(pd.read_csv('./datasets/nyt-ingredients-snapshot-2015.csv')['input'].dropna())\n",
    "random.shuffle(full_dataset)\n",
    "\n",
    "TRAIN_VAL_SPLIT = int(len(full_dataset) * 0.7)\n",
    "train_source = full_dataset[:TRAIN_VAL_SPLIT]\n",
    "test_source = full_dataset[TRAIN_VAL_SPLIT:]\n",
    "print(\"Обучающая выборка\", len(train_source))\n",
    "print(\"Тестовая выборка\", len(test_source))\n",
    "print()\n",
    "print('\\n'.join(train_source[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # токенизируем\n",
    "# train_tokenized = tokenize_corpus(\n",
    "#     train_source,\n",
    "#     tokenizer=tokenize_text_simple_regex,\n",
    "#     min_token_size=0,\n",
    "# )\n",
    "# test_tokenized = tokenize_corpus(\n",
    "#     test_source,\n",
    "#     tokenizer=tokenize_text_simple_regex,\n",
    "#     min_token_size=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = en_core_web_lg.load(disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus_with_spacy(\n",
    "    texts, spacy_nlp, lemmatize=False, with_pos=False, delim=\"_\"\n",
    "):\n",
    "    tokenized_corpus = list(spacy_nlp.pipe(texts))\n",
    "    result = []\n",
    "\n",
    "    for doc in tokenized_corpus:\n",
    "        tokenized_text = []\n",
    "\n",
    "        for token in doc:\n",
    "            token_cont = token.text if not lemmatize else token.lemma_\n",
    "\n",
    "            if with_pos:\n",
    "                token_cont += delim + token.pos_\n",
    "\n",
    "            tokenized_text.append(token_cont)\n",
    "\n",
    "        result.append(tokenized_text)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "LEMMATIZE_MODE_SPACY_TOKENIZER = True\n",
    "POS_ADD_MODE_SPACY_TOKENIZER = True\n",
    "DELIM = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем с SpaCy\n",
    "train_tokenized = tokenize_corpus_with_spacy(\n",
    "    train_source,\n",
    "    spacy_nlp,\n",
    "    lemmatize=LEMMATIZE_MODE_SPACY_TOKENIZER,\n",
    "    with_pos=POS_ADD_MODE_SPACY_TOKENIZER,\n",
    "    delim=DELIM,\n",
    ")\n",
    "test_tokenized = tokenize_corpus_with_spacy(\n",
    "    test_source,\n",
    "    spacy_nlp,\n",
    "    lemmatize=LEMMATIZE_MODE_SPACY_TOKENIZER,\n",
    "    with_pos=POS_ADD_MODE_SPACY_TOKENIZER,\n",
    "    delim=DELIM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4_NUM cup_NOUN sour_ADJ cream_NOUN\n",
      "10_NUM ounce_NOUN swordfish_NOUN ,_PUNCT red_ADJ snapper_NOUN or_CCONJ other_ADJ firm_NOUN -_PUNCT flesh_VERB fish_NOUN\n",
      "1_NUM tablespoon_NOUN mince_VERB basil_NOUN leave_VERB\n",
      "handful_ADJ fresh_ADJ parsley_NOUN ,_PUNCT finely_ADV mince_VERB\n",
      "4_NUM ounce_NOUN lard_NOUN or_CCONJ butter_NOUN ,_PUNCT plus_CCONJ more_ADJ for_ADP brush_VERB top_NOUN\n",
      "4_NUM to_PART 5_NUM green_ADJ cardamom_NOUN pod_NOUN\n",
      "1_NUM stick_NOUN (_PUNCT 1/4_NUM pound_NOUN )_PUNCT unsalted_ADJ butter_NOUN ,_PUNCT soften_VERB\n",
      "1/4_NUM teaspoon_NOUN red_ADJ pepper_NOUN flake_NOUN ,_PUNCT preferably_ADV turkish_ADJ or_CCONJ Aleppo_PROPN (_PUNCT see_VERB note_NOUN )_PUNCT ,_PUNCT more_ADJ to_PART taste_VERB\n",
      "1_NUM tablespoon_NOUN fresh_ADJ lemon_NOUN juice_NOUN\n",
      "1/4_NUM cup_NOUN scallion_NOUN ,_PUNCT thinly_ADV slice_VERB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\" \".join(sent) for sent in train_tokenized[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:32.325205Z",
     "start_time": "2019-10-29T19:19:32.140837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря 2774\n",
      "[('<PAD>', 0), ('1_NUM', 1), (',_PUNCT', 2), ('cup_NOUN', 3), ('2_NUM', 4), ('tablespoon_NOUN', 5), ('1/2_NUM', 6), ('teaspoon_NOUN', 7), ('and_CCONJ', 8), ('or_CCONJ', 9)]\n"
     ]
    }
   ],
   "source": [
    "# строим словарь\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=0.9, min_count=5, pad_word='<PAD>')\n",
    "print(\"Размер словаря\", len(vocabulary))\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:32.686258Z",
     "start_time": "2019-10-29T19:19:32.327711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 3 277 72\n",
      "117 26 1008 2 46 655 9 156 750 11 815 235\n",
      "1 5 32 123 71\n",
      "1446 22 62 2 28 32\n",
      "21 26 674 9 34 2 64 84 39 699 666\n",
      "21 15 73 82 399 494\n",
      "1 211 12 16 18 14 70 34 2 319\n",
      "16 7 46 17 175 2 104 1407 9 856 12 131 177 14 2 84 15 23\n",
      "1 5 22 48 44\n",
      "16 3 113 2 88 50\n"
     ]
    }
   ],
   "source": [
    "# отображаем в номера токенов\n",
    "train_token_ids = texts_to_token_ids(train_tokenized, vocabulary)\n",
    "test_token_ids = texts_to_token_ids(test_tokenized, vocabulary)\n",
    "\n",
    "print('\\n'.join(' '.join(str(t) for t in sent)\n",
    "                for sent in train_token_ids[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:32.967989Z",
     "start_time": "2019-10-29T19:19:32.688319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in train_token_ids], bins=20);\n",
    "plt.title('Гистограмма длин предложений');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:33.001487Z",
     "start_time": "2019-10-29T19:19:32.970153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 16,   3, 277,  72,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "MAX_SENTENCE_LEN = 20\n",
    "train_dataset = PaddedSequenceDataset(train_token_ids,\n",
    "                                      np.zeros(len(train_token_ids)),\n",
    "                                      out_len=MAX_SENTENCE_LEN)\n",
    "test_dataset = PaddedSequenceDataset(test_token_ids,\n",
    "                                     np.zeros(len(test_token_ids)),\n",
    "                                     out_len=MAX_SENTENCE_LEN)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм обучения - Skip Gram Negative Sampling\n",
    "\n",
    "**Skip Gram** - предсказываем соседние слова по центральному слову\n",
    "\n",
    "**Negative Sampling** - аппроксимация softmax\n",
    "\n",
    "$$ W, D \\in \\mathbb{R}^{Vocab \\times EmbSize} $$\n",
    "\n",
    "$$ \\sum_{CenterW_i} P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) \\rightarrow \\max_{W,D} $$\n",
    "\n",
    "$$ P(CtxW_{-2}, CtxW_{-1}, CtxW_{+1}, CtxW_{+2} | CenterW_i; W, D) = \\prod_j P(CtxW_j | CenterW_i; W, D) $$\n",
    "    \n",
    "$$ P(CtxW_j | CenterW_i; W, D) = \\frac{e^{w_i \\cdot d_j}} { \\sum_{j=1}^{|V|} e^{w_i \\cdot d_j}} = softmax \\simeq \\frac{e^{w_i \\cdot d_j^+}} { \\sum_{j=1}^{k} e^{w_i \\cdot d_j^-}}, \\quad k \\ll |V| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:33.065376Z",
     "start_time": "2019-10-29T19:19:33.003081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_diag_mask(size, radius):\n",
    "    \"\"\"Квадратная матрица размера Size x Size с двумя полосами ширины radius вдоль главной диагонали\"\"\"\n",
    "    idxs = torch.arange(size)\n",
    "    abs_idx_diff = (idxs.unsqueeze(0) - idxs.unsqueeze(1)).abs()\n",
    "    mask = ((abs_idx_diff <= radius) & (abs_idx_diff > 0)).float()\n",
    "    return mask\n",
    "\n",
    "make_diag_mask(10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negative Sampling** работает следующим образом - мы **максимизируем сумму вероятностей двух событий**: \n",
    "\n",
    "* \"этот пример центрального слова вместе с контекстными словами взят **из тренировочной выборки**\": $$ P(y=1 | CenterW_i; CtxW_j) = sigmoid(w_i \\cdot d_j) = \\frac{1}{1+e^{-w_i \\cdot d_j}} $$\n",
    "\n",
    "$$ \\\\ $$\n",
    "\n",
    "* \"этот пример центрального слова вместе со случайми контекстными словами **выдуман** \": $$ P(y=0 | CenterW_i; CtxW_{noise}) = 1 - P(y=1 | CenterW_i;  CtxW_{noise}) = \\frac{1}{1+e^{w_i \\cdot d_{noise}}} $$\n",
    "\n",
    "$$ \\\\ $$\n",
    "\n",
    "$$ NEG(CtxW_j, CenterW_i) = log(\\frac{1}{1+e^{-w_i \\cdot d_j}}) + \\sum_{l=1}^{k}log(\\frac{1}{1+e^{w_i \\cdot d_{noise_l}}})  \\rightarrow \\max_{W,D} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:33.101379Z",
     "start_time": "2019-10-29T19:19:33.068154Z"
    }
   },
   "outputs": [],
   "source": [
    "class SkipGramNegativeSamplingTrainer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, sentence_len, radius=5, negative_samples_n=5):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.negative_samples_n = negative_samples_n\n",
    "\n",
    "        self.center_emb = nn.Embedding(self.vocab_size, emb_size, padding_idx=0)\n",
    "        self.center_emb.weight.data.uniform_(-1.0 / emb_size, 1.0 / emb_size)\n",
    "        self.center_emb.weight.data[0] = 0\n",
    "\n",
    "        self.context_emb = nn.Embedding(self.vocab_size, emb_size, padding_idx=0)        \n",
    "        self.context_emb.weight.data.uniform_(-1.0 / emb_size, 1.0 / emb_size)\n",
    "        self.context_emb.weight.data[0] = 0\n",
    "\n",
    "        self.positive_sim_mask = make_diag_mask(sentence_len, radius)\n",
    "    \n",
    "    def forward(self, sentences):\n",
    "        \"\"\"sentences - Batch x MaxSentLength - идентификаторы токенов\"\"\"\n",
    "        batch_size = sentences.shape[0]\n",
    "        center_embeddings = self.center_emb(sentences)  # Batch x MaxSentLength x EmbSize\n",
    "\n",
    "        # оценить сходство с настоящими соседними словами\n",
    "        positive_context_embs = self.context_emb(sentences).permute(0, 2, 1)  # Batch x EmbSize x MaxSentLength\n",
    "        positive_sims = torch.bmm(center_embeddings, positive_context_embs)  # Batch x MaxSentLength x MaxSentLength\n",
    "        positive_probs = torch.sigmoid(positive_sims)\n",
    "\n",
    "        # увеличить оценку вероятности встретить эти пары слов вместе\n",
    "        positive_mask = self.positive_sim_mask.to(positive_sims.device)\n",
    "        positive_loss = F.binary_cross_entropy(positive_probs * positive_mask,\n",
    "                                               positive_mask.expand_as(positive_probs))\n",
    "\n",
    "        # выбрать случайные \"отрицательные\" слова\n",
    "        negative_words = torch.randint(1, self.vocab_size,\n",
    "                                       size=(batch_size, self.negative_samples_n),\n",
    "                                       device=sentences.device)  # Batch x NegSamplesN\n",
    "        negative_context_embs = self.context_emb(negative_words).permute(0, 2, 1)  # Batch x EmbSize x NegSamplesN\n",
    "        negative_sims = torch.bmm(center_embeddings, negative_context_embs)  # Batch x MaxSentLength x NegSamplesN\n",
    "        \n",
    "        # уменьшить оценку вероятность встретить эти пары слов вместе\n",
    "        negative_loss = F.binary_cross_entropy_with_logits(negative_sims,\n",
    "                                                           negative_sims.new_zeros(negative_sims.shape))\n",
    "\n",
    "        return positive_loss + negative_loss\n",
    "\n",
    "\n",
    "def no_loss(pred, target):\n",
    "    \"\"\"Фиктивная функция потерь - когда модель сама считает функцию потерь\"\"\"\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = len(vocabulary)\n",
    "\n",
    "# NEGATIVE_SAMPLES_N = 25\n",
    "# BATCH_SIZE = 8\n",
    "# LEARNING_RATE = 1e-2\n",
    "# RADIUS = 5\n",
    "\n",
    "# EMBEDDING_SIZE = 100\n",
    "# EPOCH_N = 2\n",
    "\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "\n",
    "NEGATIVE_SAMPLES_N = 25\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-2\n",
    "RADIUS = 3\n",
    "\n",
    "EMBEDDING_SIZE = 100\n",
    "EPOCH_N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настройки: VOCAB_SIZE = 2774, NEGATIVE_SAMPLES_N = 25, BATCH_SIZE = 32, LEARNING_RATE = 0.01, RADIUS = 3, EMBEDDING_SIZE = 100, EPOCH_N = 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Настройки: VOCAB_SIZE = {VOCAB_SIZE}, NEGATIVE_SAMPLES_N = {NEGATIVE_SAMPLES_N}, BATCH_SIZE = {BATCH_SIZE}, LEARNING_RATE = {LEARNING_RATE}, RADIUS = {RADIUS}, EMBEDDING_SIZE = {EMBEDDING_SIZE}, EPOCH_N = {EPOCH_N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:19:33.130307Z",
     "start_time": "2019-10-29T19:19:33.103036Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SkipGramNegativeSamplingTrainer(VOCAB_SIZE, EMBEDDING_SIZE, MAX_SENTENCE_LEN,\n",
    "                                          radius=RADIUS, negative_samples_n=NEGATIVE_SAMPLES_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.830221Z",
     "start_time": "2019-10-29T19:19:33.132062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Эпоха: 2001 итераций, 5.12 сек\n",
      "Среднее значение функции потерь на обучении 0.6837635520158679\n",
      "Среднее значение функции потерь на валидации 0.6747461413612956\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 2001 итераций, 5.62 сек\n",
      "Среднее значение функции потерь на обучении 0.6734967747668753\n",
      "Среднее значение функции потерь на валидации 0.6726144930661754\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 2001 итераций, 6.85 сек\n",
      "Среднее значение функции потерь на обучении 0.6721450676922796\n",
      "Среднее значение функции потерь на валидации 0.6720971529720936\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 2001 итераций, 5.52 сек\n",
      "Среднее значение функции потерь на обучении 0.6712723651091973\n",
      "Среднее значение функции потерь на валидации 0.6723189664568625\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 2001 итераций, 5.21 сек\n",
      "Среднее значение функции потерь на обучении 0.6706537901312634\n",
      "Среднее значение функции потерь на валидации 0.6723375288839494\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 2001 итераций, 6.16 сек\n",
      "Среднее значение функции потерь на обучении 0.6673403470769994\n",
      "Среднее значение функции потерь на валидации 0.6691000283722938\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 2001 итераций, 5.52 сек\n",
      "Среднее значение функции потерь на обучении 0.6651490668187673\n",
      "Среднее значение функции потерь на валидации 0.6682874834061805\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 2001 итераций, 5.22 сек\n",
      "Среднее значение функции потерь на обучении 0.6651377843535584\n",
      "Среднее значение функции потерь на валидации 0.6681004628814211\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 2001 итераций, 5.64 сек\n",
      "Среднее значение функции потерь на обучении 0.664823283111376\n",
      "Среднее значение функции потерь на валидации 0.6677502479277742\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 2001 итераций, 5.53 сек\n",
      "Среднее значение функции потерь на обучении 0.6641513660870333\n",
      "Среднее значение функции потерь на валидации 0.6678653430058319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss, best_model = train_eval_loop(trainer,\n",
    "                                            train_dataset,\n",
    "                                            test_dataset,\n",
    "                                            no_loss,\n",
    "                                            lr=LEARNING_RATE,\n",
    "                                            epoch_n=EPOCH_N,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            device='cpu',\n",
    "                                            early_stopping_patience=10,\n",
    "                                            max_batches_per_epoch_train=2000,\n",
    "                                            max_batches_per_epoch_val=len(test_dataset),\n",
    "                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=1, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.862018Z",
     "start_time": "2019-10-29T19:20:12.832046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "torch.save(trainer.state_dict(), 'models/sgns.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.888270Z",
     "start_time": "2019-10-29T19:20:12.864706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "trainer.load_state_dict(torch.load('models/sgns.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуем характеристики полученных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.919904Z",
     "start_time": "2019-10-29T19:20:12.890671Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = Embeddings(trainer.center_emb.weight.detach().cpu().numpy(), vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"embeddings.most_similar('chicken')\")\n",
    "# # print(\"Out:\")\n",
    "# embeddings.most_similar('chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"embeddings.analogy('cake', 'cacao', 'cheese')\")\n",
    "# # print(\"Out:\")\n",
    "# embeddings.analogy('cake', 'cacao', 'cheese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'merlot', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']\n",
    "# test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']\n",
    "# test_vectors = embeddings.get_vectors(*test_words)\n",
    "# print(test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches((10, 10))\n",
    "# plot_vectors(test_vectors, test_words, how='svd', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.most_similar('chicken_NOUN')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('chicken_NOUN', 0.9999471),\n",
       " ('stock_NOUN', 0.5937826),\n",
       " ('turkey_NOUN', 0.56244886),\n",
       " ('duck_NOUN', 0.5497401),\n",
       " ('broth_NOUN', 0.53921604),\n",
       " ('pheasant_NOUN', 0.5330454),\n",
       " ('veal_NOUN', 0.5325875),\n",
       " ('beef_NOUN', 0.50705683),\n",
       " ('skate_NOUN', 0.5021599),\n",
       " ('breast_NOUN', 0.5007763)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"embeddings.most_similar('chicken_NOUN')\")\n",
    "# print(\"Out:\")\n",
    "embeddings.most_similar('chicken_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.analogy('cake_NOUN', 'cacao_NOUN', 'cheese_NOUN')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cacao_NOUN', 1.0826366),\n",
       " ('cheese_NOUN', 0.96782404),\n",
       " ('70_NUM', 0.73867005),\n",
       " ('queso_NOUN', 0.71897376),\n",
       " ('percent_NOUN', 0.70799565),\n",
       " ('solid_NOUN', 0.6984317),\n",
       " ('blanco_NOUN', 0.67209536),\n",
       " ('Muenster_PROPN', 0.67171854),\n",
       " ('Gruyère_PROPN', 0.6555697),\n",
       " ('chocolate_NOUN', 0.6345702)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"embeddings.analogy('cake_NOUN', 'cacao_NOUN', 'cheese_NOUN')\")\n",
    "# print(\"Out:\")\n",
    "embeddings.analogy('cake_NOUN', 'cacao_NOUN', 'cheese_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.942708Z",
     "start_time": "2019-10-29T19:20:12.921619Z"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings.most_similar('chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.965936Z",
     "start_time": "2019-10-29T19:20:12.944423Z"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings.analogy('cake', 'cacao', 'cheese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:12.991060Z",
     "start_time": "2019-10-29T19:20:12.967532Z"
    }
   },
   "outputs": [],
   "source": [
    "# # test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'merlot', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']\n",
    "# test_words = ['salad', 'fish', 'salmon', 'sauvignon', 'beef', 'pork', 'steak', 'beer', 'cake', 'coffee', 'sausage', 'wine', 'zinfandel', 'trout', 'chardonnay', 'champagne', 'cacao']\n",
    "# test_vectors = embeddings.get_vectors(*test_words)\n",
    "# print(test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:13.318676Z",
     "start_time": "2019-10-29T19:20:12.996595Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches((10, 10))\n",
    "# plot_vectors(test_vectors, test_words, how='svd', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение Word2Vec с помощью Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:13.613797Z",
     "start_time": "2019-10-29T19:20:13.321353Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.075005Z",
     "start_time": "2019-10-29T19:20:13.615729Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(sentences=train_tokenized, size=100,\n",
    "                                  window=5, min_count=5, workers=4,\n",
    "                                  sg=1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.109583Z",
     "start_time": "2019-10-29T19:20:17.076599Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec.wv.most_similar('chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.176357Z",
     "start_time": "2019-10-29T19:20:17.112948Z"
    }
   },
   "outputs": [],
   "source": [
    "gensim_words = [w for w in test_words if w in word2vec.wv.vocab]\n",
    "gensim_vectors = np.stack([word2vec.wv[w] for w in gensim_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.428874Z",
     "start_time": "2019-10-29T19:20:17.179311Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "plot_vectors(gensim_vectors, test_words, how='svd', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка предобученного Word2Vec\n",
    "\n",
    "Источники готовых векторов:\n",
    "\n",
    "https://rusvectores.org/ru/ - для русского языка\n",
    "\n",
    "https://wikipedia2vec.github.io/wikipedia2vec/pretrained/ - много разных языков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.460133Z",
     "start_time": "2019-10-29T19:20:17.430563Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:20:17.980509Z",
     "start_time": "2019-10-29T19:20:17.462239Z"
    }
   },
   "outputs": [],
   "source": [
    "available_models = api.info()['models'].keys()\n",
    "print('\\n'.join(available_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:22:12.649035Z",
     "start_time": "2019-10-29T19:20:17.984118Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pretrained = api.load('word2vec-google-news-300')  # > 1.5 GB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:22:12.651388Z",
     "start_time": "2019-10-29T19:19:29.817Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained.most_similar('cheese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:22:12.652649Z",
     "start_time": "2019-10-29T19:19:29.820Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained.most_similar(positive=['man', 'queen'], negative=['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:22:12.653584Z",
     "start_time": "2019-10-29T19:19:29.823Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_words = [w for w in test_words if w in pretrained.vocab]\n",
    "pretrained_vectors = np.stack([pretrained[w] for w in pretrained_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:22:12.654594Z",
     "start_time": "2019-10-29T19:19:29.828Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "plot_vectors(pretrained_vectors, test_words, how='svd', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "* Реализовали Skip Gram Negative Sampling на PyTorch\n",
    "* Обучили на корпусе рецептов\n",
    "    * Сходство слов модель выучила неплохо\n",
    "    * Для аналогий мало данных\n",
    "* Обучили SGNS с помощью библиотеки Gensim\n",
    "* Загрузили веса Word2Vec, полученные с помощью большого корпуса (GoogleNews)\n",
    "    * Списки похожих слов отличаются!\n",
    "    * Аналогии работают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
